---
title: "Workflow: Visium CRC"
output: html_notebook
---

Source:https://lmweber.org/OSTA/pages/seq-workflow-visium-crc.html

> . Commercially available since 2024, Visium HD advanced the platform’s resolution from 55 µm spots to bins of subcellular resolution (2 µm). 
> In this workflow, we will demonstrate common analysis steps with a Visium HD dataset on colorectal cancer (Oliveira et al. 2024).

> In this demo, we perform deconvolution on 16 µm bins and compare the concordance with results on 8 µm bins, provided by 10x Genomics. 


```{r}
library(Banksy)
library(BiocParallel)
library(DropletUtils)
library(ggplot2)
library(ggspavis)
library(igraph)
library(OSTA.data)
library(patchwork)
library(pheatmap)
library(scater)
library(scran)
library(scuttle)
library(spacexr)
library(SpatialExperiment)
library(SpotSweeper)
library(Statial)
library(tidyr)
library(VisiumIO)
```



This is the 8um bins:
```{r}
# retrieve dataset from OSF repo
id <- "VisiumHD_HumanColon_Oliveira"
pa <- OSTA.data_load(id)
dir.create(td <- tempfile())
unzip(pa, exdir=td)
# read 8um bins into 'SpatialExperiment'
vhd8 <- VisiumIO::TENxVisiumHD(
    spacerangerOut=td, 
    processing="filtered",
    format="h5", 
    images="lowres", 
    bin_size="008") |>
    import()
# use gene symbols as feature names
gs <- rowData(vhd8)$Symbol
rownames(vhd8) <- make.unique(gs)
colnames(vhd8) <- vhd8$barcode # TODO: VisiumIO bug?
vhd8
```


>These data come with bin-level annotations from deconvolution estimates by RCTD, implemented in `spacexr`. 
> Specifically, two sets of labels are available that correspond to the most and second most frequent of 38 cell types per bin, respectively: 

```{r}
# retrieve annotations
gz <- "binned_outputs/square_008um/deconvolution.csv.gz"
df <- read.csv(file.path(td, gz), row.names=2)
head(df <- df[complete.cases(df), -1])
```

SJS getting that metadata into the colData - 

```{r}
# keep only annotated bins
vhd8 <- vhd8[, rownames(df)]
names(df) <- c("DeconClass", "DeconLabel1", "DeconLabel2")
colData(vhd8)[names(df)] <- df
```


Very pretty, too many freaking colors:
```{r, fig.width = 10}
lab <- grep("Label", names(cd <- colData(vhd8)), value=TRUE)
pal <- hcl.colors(length(unique(unlist(cd[lab]))), "Spectral")
lapply(lab, \(.) {
    p <- plotCoords(vhd8, annotate=., point_size=0.2) + ggtitle(.)
    p$layers[[1]]$aes_params$shape <- 16
    p$layers[[1]]$aes_params$stroke <- 0
    p
}) |>
    wrap_plots(nrow=1, guides="collect") &
    scale_color_manual(NULL, values=pal) &
    theme(legend.key.size=unit(0, "lines"))
```



Now we're reading in the 16umversion!


```{r}
# read 16um bins into 'SpatialExperiment'
vhd16 <- TENxVisiumHD(
    spacerangerOut=td,
    processing="filtered",
    format="h5",
    images="lowres",
    bin_size="016") |>
    import()
# use symbols as feature names
gs <- rowData(vhd16)$Symbol
rownames(vhd16) <- make.unique(gs)
colnames(vhd16) <- vhd16$barcode # TODO: VisiumIO bug?
vhd16
```

> Some global filtering based on library size is necessary to remove bins that overlay empty tissue.

```{r}
vhd16$libsize <- colSums(counts(vhd16))
```

> We can visualize such bins by zooming into an empty tissue region. On the left-hand side, one region shows a clear gap with low counts. Informed by H&E staining, bins located above tissue gaps should not be interpreted biologically, as the low counts in these bins are likely due to ambient RNA or transcript spillover. Therefore, they should be excluded from downstream analysis.

> Based on a discussion with the original author at 10x Genomics, in this dataset, 8 µm bins with a library size below 100 are removed. Since we expect a 4-fold increase in library size across all bins at 16 µm, we can set the filtering threshold to 400.

```{r}
p1 <- ggspavis::plotVisium(vhd16, annotate="libsize", 
           zoom = TRUE, show_axes = TRUE, point_size = 1.3) + 
    xlim(c(422, 442)) + ylim(c(318, 330)) + 
    facet_null() + ggtitle("16 µm - original")

vhd16 <- vhd16[, vhd16$libsize > 400]

p2 <- ggspavis::plotVisium(vhd16, annotate="libsize", 
           zoom = TRUE, show_axes = TRUE, point_size = 1.3) + 
    xlim(c(422, 442)) + ylim(c(318, 330)) + 
    facet_null() + ggtitle("16 µm - after > 400 UMI QC")

p1 | p2
```
>Clustering results generated by Space Ranger are provided for both resolutions.

SJS - by spaceranger!!!
```{r}
csv <- list.files(td, "clustering", recursive=TRUE, full.names=TRUE)
dfs <- lapply(csv, read.csv, row.names="barcode") 

colData(vhd8)$cluster <- factor(dfs[[1]][colnames(vhd8), "cluster"])
colData(vhd16)$cluster <- factor(dfs[[2]][colnames(vhd16), "cluster"])
```




```{r}
vhd16$libsize <- colSums(counts(vhd16))
```


They do some wild subsetting here to get down to only 1/64 of the total coverage area to keep runtime low.
--> SpotSweeper is much appeased with this smaller dataset, let me tell you!
```{r}
.rng <- \(spe) {
    xy <- spatialCoords(spe)*scaleFactors(spe)
    xs <- range(xy[, 1]); ys <- nrow(imgRaster(spe))-range(xy[, 2])
    x1 <- xs[1] + 4*(xs[2]-xs[1])/8; x2 <- xs[2] - 3*(xs[2]-xs[1])/8
    y1 <- ys[1] + 3*(ys[2]-ys[1])/8; y2 <- ys[2] - 4*(ys[2]-ys[1])/8
    list(box=c(x1, x2, y1, y2), cov=c(xs, ys))
}
vhd8r <- .rng(vhd8)

.sub <- function(spe, rng, roi="box") {
    xs <- rng[[roi]][c(1, 2)]
    ys <- nrow(imgRaster(spe)) - rng[[roi]][c(3,4)]
    xy <- spatialCoords(spe)*scaleFactors(spe)
    spe[, xy[, 1] > xs[1] & xy[, 1] < xs[2] & 
          xy[, 2] > ys[1] & xy[, 2] < ys[2] ]
}
.vhd16 <- .sub(spe=vhd16, rng=vhd8r)
dim(.vhd16)
```



## 14.3 QUALITY CONTROL

Ah, `SpotSweeper`!!
We use `scuttle` to do the QC, and `SpotSweeper` to find the outliers to get rid of.
Nice.
For reference: https://bioconductor.org/packages/3.22/bioc/vignettes/SpotSweeper/inst/doc/getting_started.html

```{r}
# calculate per-cell QC metrics
mt <- grepl("^MT-", rownames(.vhd16))
.vhd16 <- scuttle::addPerCellQCMetrics(.vhd16, subsets=list(mt=mt))
# determine outliers based on 
# - low log-library size
# - few uniquely detected features
# - high mitochondrial count fraction
.vhd16 <- SpotSweeper::localOutliers(.vhd16, metric="sum", direction="lower", log=TRUE)
.vhd16 <- SpotSweeper::localOutliers(.vhd16, metric="detected", direction="lower", log=TRUE)
.vhd16 <- SpotSweeper::localOutliers(.vhd16, metric="subsets_mt_percent", direction="higher", log=TRUE)
.vhd16$discard <- 
    .vhd16$sum_outliers | 
    .vhd16$detected_outliers | 
    .vhd16$subsets_mt_percent_outliers
# tabulate number of bins retained 
# vs. removed by any criterion 
table(.vhd16$discard)
```
FYI -  I tried the above chunk with the full `vhd16` dataset and it was damn slow at the `SpotSweeper` step so I killed it. This ensmallened object is way more efficient.



We can visualize this and yay it's random

```{r}
plotCoords(.vhd16, annotate="sum_outliers") + ggtitle("low_lib_size") +
plotCoords(.vhd16, annotate="detected_outliers") + ggtitle("low_n_features") +
plotCoords(.vhd16, annotate="discard") + ggtitle("discard") +
plot_layout(nrow=1, guides="collect") & theme(
    plot.title=element_text(hjust=0.5),
    legend.key.size=unit(0, "lines")) &
    guides(col=guide_legend(override.aes=list(size=3))) & 
    scale_color_manual("discard", values=c("lavender", "purple"))
```
```{r}
.vhd16 <- .vhd16[, !.vhd16$discard]
dim(.vhd16)
```

## Clustering

```{r}
.vhd16 <- logNormCounts(.vhd16)
dec <- modelGeneVar(.vhd16)
hvg <- getTopHVGs(dec, n=3e3)
```
NOTE THAT SVGs COULD BE USED INSTEAD! 


>As detailed in Chapter 23, Banksy utilizes a pair of spatial kernels to capture gene expression variation, followed by dimension reduction and graph-based clustering to identify spatial domains.

```{r}
# set seed for random number generation
# in order to make results reproducible
set.seed(112358)
# 'Banksy' parameter settings
k <- 8   # consider first order neighbors
l <- 0.2 # use little spatial information
a <- "logcounts"
xy <- c("array_row", "array_col")

# restrict to selected features
tmp <- .vhd16[hvg, ]

# compute spatially aware 'Banksy' PCs
tmp <- computeBanksy(tmp, assay_name=a, coord_names=xy, k_geom=k)
tmp <- runBanksyPCA(tmp, lambda=l, npcs=20)
reducedDim(.vhd16, "PCA") <- reducedDim(tmp)
##########################################################################################
## run UMAP (for visualization purposes only)
# .vhd16 <- runUMAP(.vhd16, dimred="PCA")
# build cellular shared nearest-neighbor (SNN) graph
g <- buildSNNGraph(.vhd16, use.dimred="PCA", type="jaccard", k=20)
# cluster using Leiden community detection algorithm
k <- cluster_leiden(g, objective_function="modularity", resolution=1.2)
table(.vhd16$Banksy <- factor(k$membership))
```



> Next, we can perform differential gene expresison (DGE) analysis to identify markers for each cluster; c.f. Section 24.2.2. We also compute the cluster-wise mean expression of selected markers:

im not making the heatmap.

```{r}
mgs <- scran::findMarkers(.vhd16, groups=.vhd16$Banksy, direction="up")
```


> Or, we can visualize the bin-wise expression of selected markers in space:

yeah!

```{r}
gs <- c("MMP2", "PIGR", "IGHG1")
ps <- lapply(gs, \(.) plotCoords(.vhd16, annotate=., assay_name="logcounts"))
wrap_plots(ps, nrow=1) & theme(
    legend.key.width=unit(0.5, "lines"),
    legend.key.height=unit(1, "lines")) &
    scale_color_gradientn(colors=rev(hcl.colors(9, "Rocket")))
```

## 14.5 DECONVOLUTION

> We will now perform deconvolution on the 16 µm binned Visium HD data. First, we retrieve matching (Chromium) scRNA-seq data, which includes low- (Level1) and high-resolution (Level2) annotations of cells into 9 respectively 31 clusters. In order to ensure similar transcriptional profile across technologies, we filter the reference population to patient 2 only.


```{r}
# retrieve dataset from OSF repository
id <- "Chromium_HumanColon_Oliveira"
pa <- OSTA.data_load(id)
dir.create(td <- tempfile())
unzip(pa, exdir=td)
# read into `SingleCellExperiment`
fs <- list.files(td, full.names=TRUE)
h5 <- grep("h5$", fs, value=TRUE)
sce <- read10xCounts(h5, col.names=TRUE)
# add cell metadata
csv <- grep("csv$", fs, value=TRUE)
cd <- read.csv(csv, row.names=1)
colData(sce)[names(cd)] <- cd[colnames(sce), ]
# use gene symbols as feature names
gs <- rowData(sce)$Symbol
rownames(sce) <- make.unique(gs)
# exclude cells deemed to be of low-quality
sce <- sce[, sce$QCFilter == "Keep"]
# subset cells from same patient
sce <- sce[, grepl("P2", sce$Patient)]
sce
```

The tutorial takes some time to look at the cell types in the sce, I'm moving on.

### 14.5.2 Simplify 8 µm annotations

> We can merge the provided deconvolution annotation "DeconLabel1" (most likely cell type for singlets, most dominant type for doublets) into a lower resolution using the single-cell reference annotations:


```{r}
i <- match(vhd8$DeconLabel1, sce$Level2)
j <- match(vhd8$DeconLabel2, sce$Level2)
vhd8$.DeconLabel1 <- sce$Level1[i]
vhd8$.DeconLabel2 <- sce$Level1[j]
vhd8 <- vhd8[, !is.na(vhd8$.DeconLabel1)]
table(vhd8$.DeconLabel1)
```
> According to RCTD, approximately 75% of the 8 µm bins are singlets:

```{r}
round(100*mean(vhd8$DeconClass == "singlet"), 2)
```
> Let us check the top-5 common doublet pairs according to the "doublet_certain" class:

```{r}
dbl <- vhd8$DeconClass == "doublet_certain"
lab <- c(".DeconLabel1", ".DeconLabel2")
df <- data.frame(colData(vhd8)[dbl, lab])
# sort as to ignore order
df <- apply(df, 1, sort)
df <- do.call(rbind, df)
names(df) <- lab
# count unique pairs
ij <- paste(df[, 1], df[, 2], sep=";")
head(sort(table(ij), decreasing=TRUE), 5)
```


### 14.5.3 Run RCTD on 16 µm bins

> We also assume there are at most two cell types in a 16 µm bin as in 8 µm, and thus we would expect a smaller proportion of singlets.

SJS: rather than downsampling as they have done here, we might borrow aggregateReference. OTOH, this is conceptually not dissimilar! Noting this is taking a DECENT AMOUNT OF TIME to run `spacexr` either way!
```{r}
# downsample to at most 4,000 cells per cluster for sce
# (this is done only to keep runtime/memory low)
cs <- split(seq_len(ncol(sce)), sce$Level1)
cs <- lapply(cs, \(.) sample(., min(length(.), 4e3)))
ncol(.sce <- sce[, unlist(cs)])
rctd_data <- createRctd(.vhd16, .sce, cell_type_col="Level1")
(res <- runRctd(rctd_data, max_cores=4, rctd_mode="doublet"))
```
```{r}
# counts rejected observations
ws <- assay(res, "weights")

ws
table(colSums(ws) == 0)
```
```{r}
# add proportion estimates as metadata
ws <- data.frame(t(as.matrix(ws)))
colData(.vhd16)[names(ws)] <- ws[colnames(.vhd16), ]
```

```{r}
# derive majority vote labels
ids <- names(ws)[apply(ws, 1, which.max)]
ids <- gsub("\\.([A-z])", " \\1", ids)
idx <- match(colnames(.vhd16), rownames(ws))
table(.vhd16$.DeconLabel1 <- factor(ids[idx]))

```



> Next, we can spatially visualize the deconvolution proportions estimates:

```{r}
lapply(names(ws), \(.) 
    plotCoords(.vhd16, annotate=., point_size=0.1)) |>
    wrap_plots(nrow=2, guides="collect") & theme(
    legend.key.width=unit(0.5, "lines"),
    legend.key.height=unit(1, "lines")) &
    scale_color_gradientn(colors=rev(hcl.colors(9, "Rocket")))
```


SKIPPING AHEAD...........


## 14.6.1 Concordance of clustering & deconvolution

uses `ggspavis`:


```{r}
plotVisium(.vhd16, annotate="cluster", zoom=TRUE, 
    point_size=1.6, pal=unname(pals::kelly())) + 
    plot_spacer() +
plotVisium(.vhd16, annotate="Banksy", zoom=TRUE, 
    point_size=1.6, pal=unname(pals::kelly())) + 
    plot_spacer() +
plotVisium(.vhd16, annotate=".DeconLabel1", zoom=TRUE, 
    point_size=1.6, pal=unname(pals::trubetskoy())) +
plot_layout(nrow=1, 
    widths=c(1, 0.05, 1, 0.05, 1)) & facet_null() &
    theme(legend.key.size=unit(0, "lines"))
```
> We observe that Banksy delineates tissue borders very well, while deconvolution provides direct biological insight into the underlying clusters. Their concordance can be visualized using a heatmap:

```{r}
fq <- prop.table(table(.vhd16$Banksy, .vhd16$.DeconLabel1), 1)
pheatmap(fq, cellwidth=10, cellheight=10, treeheight_row=5, treeheight_col=5)
```

```{r}
sessionInfo()
```
